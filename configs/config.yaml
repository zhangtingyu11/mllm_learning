defaults:
  - model: mocov1
  - dataset: cifar10

pretraining:
  epochs: 200
  batch_size: 256
  num_workers: 4
  
  optimizer:
    _target_: torch.optim.SGD
    lr: 0.0003
    momentum: 0.9
    weight_decay: 1e-4
  
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: 200
    eta_min: 0.0

finetuning:
  epochs: 10
  batch_size: 256
  
  optimizer:
    _target_: torch.optim.SGD
    lr: 0.02
    momentum: 0.9
    weight_decay: 1e-4
  
  scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    milestones: [5, 8]
    gamma: 0.1
